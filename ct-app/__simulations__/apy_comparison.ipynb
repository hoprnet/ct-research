{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "from math import log10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from matplotlib.axes import Axes\n",
    "from IPython.display import display\n",
    "import requests\n",
    "import os \n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables \n",
    "load_dotenv('simulation.env')\n",
    "\n",
    "# Access environment variables \n",
    "subgraph_url = os.environ['SUBGRAPH_URL']\n",
    "api_host = os.environ['API_HOST']\n",
    "api_key = os.environ['API_KEY']\n",
    "\n",
    "if 'SUBGRAPH_URL' in os.environ and 'API_HOST' in os.environ and 'API_KEY' in os.environ:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get safe balances from subgraph and channel balances from the topology api endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subgraph_data():\n",
    "    \"\"\"\n",
    "    This function retrieves safe_address-node_address-balance links from the\n",
    "    specified subgraph using pagination.\n",
    "    \"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "            query SafeNodeBalance($first: Int, $skip: Int) {\n",
    "                safes(first: $first, skip: $skip) {\n",
    "                    registeredNodesInNetworkRegistry {\n",
    "                    node {\n",
    "                        id\n",
    "                    }\n",
    "                    safe {\n",
    "                        id\n",
    "                        balance {\n",
    "                        wxHoprBalance\n",
    "                        }\n",
    "                    }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"query\": query,\n",
    "        \"variables\": {\n",
    "            \"first\": 1000,\n",
    "            \"skip\": 0,\n",
    "        },\n",
    "    }\n",
    "    subgraph_dict = {}\n",
    "    more_content_available = True\n",
    "    pagination_skip_size = 1000\n",
    "\n",
    "    while more_content_available:\n",
    "        try:\n",
    "            response = requests.post(subgraph_url, json=data)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Received status code {response.status_code} when querying The Graph API\")\n",
    "                break\n",
    "\n",
    "            json_data = response.json()\n",
    "\n",
    "        except requests.exceptions.RequestException:\n",
    "            print(\"An error occurred while sending the request to subgraph endpoint\")\n",
    "            return {}\n",
    "        except ValueError:\n",
    "            print(\"An error occurred while parsing the response as JSON from subgraph endpoint\")\n",
    "            return {}\n",
    "        except Exception:\n",
    "            print(\"An unexpected error occurred\")\n",
    "            return {}\n",
    "\n",
    "        safes = json_data[\"data\"][\"safes\"]\n",
    "        for safe in safes:\n",
    "            for node in safe[\"registeredNodesInNetworkRegistry\"]:\n",
    "                node_address = node[\"node\"][\"id\"]\n",
    "                wxHoprBalance = node[\"safe\"][\"balance\"][\"wxHoprBalance\"]\n",
    "                safe_address = node[\"safe\"][\"id\"]\n",
    "                subgraph_dict[node_address] = {\n",
    "                    \"safe_address\": safe_address,\n",
    "                    \"wxHOPR_balance\": wxHoprBalance,\n",
    "                }\n",
    "\n",
    "        # Increment skip for the next iteration\n",
    "        data[\"variables\"][\"skip\"] += pagination_skip_size\n",
    "        more_content_available = len(safes) == pagination_skip_size\n",
    "\n",
    "    return subgraph_dict\n",
    "\n",
    "def get_unique_nodeAddress_peerId_aggbalance_links(api_url, api_key):\n",
    "    \"\"\"\n",
    "    Returns a dict containing all unique source_peerId-source_address links.\n",
    "    \"\"\"\n",
    "    channel_url = \"http://{}:3001/api/v3/channels/?includingClosed=false&fullTopology=true\".format(api_host)\n",
    "    headers = {'X-Auth-Token': api_key}\n",
    "    response = requests.request(\"GET\", channel_url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Could not fetch channel information. Status code: {}\".format(response.status_code))\n",
    "        return {}\n",
    "    \n",
    "    response = response.json()\n",
    "\n",
    "    if 'all' not in response:\n",
    "            print(\"Response does not contain `all`\")\n",
    "            return {}\n",
    "\n",
    "    peerid_address_aggbalance_links = {}\n",
    "    for item in response[\"all\"]:\n",
    "        if \"sourcePeerId\" not in item or \"sourceAddress\" not in item:\n",
    "            print(\"Response does not contain `source_peerid` or `source_address`\")\n",
    "            continue\n",
    "\n",
    "        if \"status\" not in item:\n",
    "            print(\"Response does not contain `status`\")\n",
    "            continue\n",
    "\n",
    "        source_peer_id = item[\"sourcePeerId\"]\n",
    "        source_address = item[\"sourceAddress\"]\n",
    "        balance = int(item[\"balance\"]) / 1e18\n",
    "\n",
    "        if item[\"status\"] != \"Open\":\n",
    "            # Other Statuses: \"Waiting for commitment\", \"Closed\", \"Pending to close\"\n",
    "            # Ensures that nodes must have at least 1 open channel in to receive ct\n",
    "            continue\n",
    "\n",
    "        if source_peer_id not in peerid_address_aggbalance_links:\n",
    "            peerid_address_aggbalance_links[source_peer_id] = {\n",
    "                \"source_node_address\": source_address,\n",
    "                \"channels_balance\": balance,\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            peerid_address_aggbalance_links[source_peer_id][\n",
    "                \"channels_balance\"\n",
    "            ] += balance\n",
    "\n",
    "    return peerid_address_aggbalance_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "12D3KooWH9rfYNKMkNncYJxS7BH41ThPZUYe3FNkbfmJAa4n5r3x: {'source_node_address': '0x5a5bf3d3ce59cd304f198b86c1a78adfadf31f83', 'channels_balance': 9202.300000000007}\n",
      "12D3KooWL16nW1Z2dLvyZWzr9ZZwoLTeuSfaKSeX2BjucHwSoEwJ: {'source_node_address': '0xd30f8f6e5865d7ec947e101b1d6a183e9776ba40', 'channels_balance': 7755.100000000006}\n",
      "12D3KooWGyY39vD8J2VGEDjTCD3eEyvV4YrnKM9NCQa6SYJKczrR: {'source_node_address': '0xcbe8726c80cc0d7751b9545dd5a4b5b0e53e383d', 'channels_balance': 7754.900000000006}\n",
      "12D3KooWNYi2kG5cdeEUBvjemZRUkPVmAeXsSGVrX9QHnEiMfh8w: {'source_node_address': '0xa4642c066c1f8927db9d34abab599af784a2cff0', 'channels_balance': 9102.300000000005}\n",
      "12D3KooWScC7bj5YdjDLDX3ibxQjkJLeHPRGk4fdNr7jWn9ugYko: {'source_node_address': '0xfbfc5497e511ebed91fb467fcb032046a5ad5e49', 'channels_balance': 0.24999999999999992}\n"
     ]
    }
   ],
   "source": [
    "topology_data = get_unique_nodeAddress_peerId_aggbalance_links(api_host, api_key)\n",
    "\n",
    "print(len(topology_data))\n",
    "\n",
    "print_size = 5 \n",
    "\n",
    "for key, value in list(topology_data.items())[:print_size]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "0xb55ba361c60ce0851f1f3451225b2f953ee70404: {'safe_address': '0x00133125ccdf4ea1231a47e073c616f358b2d5a8', 'wxHOPR_balance': '12258.755553838447062483'}\n",
      "0x2168fcd793a3967fa4bdd66f534c4fc811124439: {'safe_address': '0x01f1d2f347ea987b5cf3ed383146feda5265f38a', 'wxHOPR_balance': '46412.387878358780883268'}\n",
      "0xed04f9fbf9160793fff7532df3860c70862bff4e: {'safe_address': '0x0420bd44fe87a855a11c9fd42b3f42203b03dec9', 'wxHOPR_balance': '30000.007400087394399044'}\n",
      "0xfcc30ccecf890362d66194659f4850acbe84b08b: {'safe_address': '0x042ddd9d9b99ed1a08eb5c5a3feae5e7a1732e82', 'wxHOPR_balance': '10000'}\n",
      "0xf3e7672a909fd8c113fc5c53dda1f38f79d7a184: {'safe_address': '0x04b21235a04d7468bdd79de8a68341b7be0a71fa', 'wxHOPR_balance': '61208.146712387571348229'}\n"
     ]
    }
   ],
   "source": [
    "subgraph_data = get_subgraph_data()\n",
    "print(len(subgraph_data))\n",
    "\n",
    "print_size = 5 \n",
    "\n",
    "for key, value in list(subgraph_data.items())[:print_size]:\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Subgraph and Topology Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_topology_subgraph(topology_dict: dict, subgraph_dict: dict):\n",
    "    \"\"\"\n",
    "    Merge metrics and subgraph data with the unique peer IDs, addresses,\n",
    "    balance links.\n",
    "    :param: topology_dict: A dict mapping peer IDs to node addresses.\n",
    "    :param: subgraph_dict: A dict containing subgraph data with safe address as the key.\n",
    "    :returns: A dict with peer ID as the key and the merged information.\n",
    "    \"\"\"\n",
    "    merged_result = {}\n",
    "\n",
    "    # Merge based on peer ID with the channel topology as the baseline\n",
    "    for peer_id, data in topology_dict.items():\n",
    "        seen_in_subgraph = False\n",
    "\n",
    "        source_node_address = data[\"source_node_address\"]\n",
    "        if source_node_address in subgraph_dict:\n",
    "            subgraph_data = subgraph_dict[source_node_address]\n",
    "            data[\"safe_address\"] = subgraph_data[\"safe_address\"]\n",
    "            data[\"safe_balance\"] = float(subgraph_data[\"wxHOPR_balance\"])\n",
    "            data[\"total_balance\"] = data[\"channels_balance\"] + data[\"safe_balance\"]\n",
    "\n",
    "            seen_in_subgraph = True\n",
    "            # print(f\"Source node address for {peer_id} found in subgraph\")\n",
    "\n",
    "        if seen_in_subgraph:\n",
    "            merged_result[peer_id] = data\n",
    "\n",
    "    return merged_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "12D3KooWH9rfYNKMkNncYJxS7BH41ThPZUYe3FNkbfmJAa4n5r3x: {'source_node_address': '0x5a5bf3d3ce59cd304f198b86c1a78adfadf31f83', 'channels_balance': 9202.300000000007, 'safe_address': '0xdf9be8bdb5ae4a130e861e5158c95667e7b2c0cb', 'safe_balance': 15817.7, 'total_balance': 25020.000000000007}\n",
      "12D3KooWL16nW1Z2dLvyZWzr9ZZwoLTeuSfaKSeX2BjucHwSoEwJ: {'source_node_address': '0xd30f8f6e5865d7ec947e101b1d6a183e9776ba40', 'channels_balance': 7755.100000000006, 'safe_address': '0x4afa6a5265ae7ba332e886be3bce5b16c861dd9f', 'safe_balance': 17264.9, 'total_balance': 25020.000000000007}\n",
      "12D3KooWGyY39vD8J2VGEDjTCD3eEyvV4YrnKM9NCQa6SYJKczrR: {'source_node_address': '0xcbe8726c80cc0d7751b9545dd5a4b5b0e53e383d', 'channels_balance': 7754.900000000006, 'safe_address': '0x5445a497292c8e669e7d3419be68de23c450c56f', 'safe_balance': 17265.1, 'total_balance': 25020.000000000004}\n",
      "12D3KooWNYi2kG5cdeEUBvjemZRUkPVmAeXsSGVrX9QHnEiMfh8w: {'source_node_address': '0xa4642c066c1f8927db9d34abab599af784a2cff0', 'channels_balance': 9102.300000000005, 'safe_address': '0xc5e2d5ba66916ef8413a87e3098117c6ac596597', 'safe_balance': 15917.7, 'total_balance': 25020.000000000007}\n",
      "12D3KooWScC7bj5YdjDLDX3ibxQjkJLeHPRGk4fdNr7jWn9ugYko: {'source_node_address': '0xfbfc5497e511ebed91fb467fcb032046a5ad5e49', 'channels_balance': 0.24999999999999992, 'safe_address': '0x08bb65f98e81b108758e03cf1e9ca763dad72abe', 'safe_balance': 9.75, 'total_balance': 10.0}\n"
     ]
    }
   ],
   "source": [
    "merged_data = merge_topology_subgraph(topology_data, subgraph_data)\n",
    "print(len(merged_data))\n",
    "\n",
    "print_size = 5 \n",
    "\n",
    "for key, value in list(merged_data.items())[:print_size]:\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stake_transformation(values, slope, curvature, threshold):\n",
    "    transformed_stakes = []\n",
    "\n",
    "    for x in values:\n",
    "        if x <= 10e3:\n",
    "            transformed_stakes.append(1e-20)\n",
    "        elif x <= threshold:\n",
    "            f_x = slope * x\n",
    "            transformed_stakes.append(f_x)\n",
    "        else:\n",
    "            g_x = slope * threshold  + (x - threshold) ** (1 / curvature)\n",
    "            transformed_stakes.append(g_x)\n",
    "\n",
    "    return transformed_stakes\n",
    "\n",
    "def compute_probabilities(stakes: list):\n",
    "    sum_stakes = sum(stakes)\n",
    "    return [s / sum_stakes for s in stakes]\n",
    "\n",
    "def compute_rewards(probabilities: list, budget: int):\n",
    "    return [p * budget for p in probabilities]\n",
    "\n",
    "def compute_apy(opt: dict, data: list, percentage: bool = False, average: bool = True, on_stake: bool = False):\n",
    "    transformed_stakes = stake_transformation(data, **opt[\"model_arguments\"])\n",
    "\n",
    "    probabilities = compute_probabilities(transformed_stakes)\n",
    "\n",
    "    rewards = compute_rewards(probabilities, opt[\"budget\"])\n",
    "\n",
    "    if percentage:\n",
    "        factor = 100\n",
    "    else:\n",
    "        factor = 1\n",
    "\n",
    "    period_apy = [r / s for r, s in zip(rewards, data if on_stake else transformed_stakes)]\n",
    "    yearly_apy = [apy * 12 / opt[\"period_in_months\"] * factor for apy in period_apy]\n",
    "    \n",
    "    apy = sum(yearly_apy) / len(yearly_apy) if average else yearly_apy  \n",
    "  \n",
    "    return apy\n",
    "\n",
    "def factor_and_prefix(value):\n",
    "    factor = int(int(log10(value))/3)*3\n",
    "    if factor < 3:\n",
    "        prefix = \"\"\n",
    "    elif factor < 6:\n",
    "        prefix = \"k\"\n",
    "    elif factor < 9:\n",
    "        prefix = \"M\"\n",
    "\n",
    "    return 10**factor, prefix\n",
    "\n",
    "def probabilistic_apy(datas: list[list], options: list[dict], steps:int = 100):\n",
    "    result_template = {\"apys\": [], \"average\": 0}\n",
    "\n",
    "    results = [deepcopy(result_template) for _ in range(len(options))]\n",
    "\n",
    "    for idx, opt in enumerate(options):\n",
    "        for _ in range(steps):\n",
    "            stakes = []\n",
    "            for data, count in zip(datas, opt[\"data_count\"]):\n",
    "                if not count:\n",
    "                    continue\n",
    "                if count == \"all\":\n",
    "                    stakes.extend(data)\n",
    "                else:\n",
    "                    stakes.extend(random.sample(data, count))\n",
    "\n",
    "            tf_stakes = stake_transformation(stakes, **opt[\"model_arguments\"])\n",
    "            \n",
    "            apy = compute_apy(opt, tf_stakes, percentage=False)\n",
    "\n",
    "            results[idx][\"apys\"].append(apy)\n",
    "\n",
    "        results[idx][\"average\"] = np.mean(results[idx][\"apys\"])\n",
    "        results[idx][\"std\"] = np.std(results[idx][\"apys\"])\n",
    "\n",
    "    return results\n",
    "\n",
    "def generate_simulation_graph(datas:list[list], options: list[dict], steps: int = 200, title: str = None, cols:int=3):\n",
    "    rows = int(len(options) / cols + 0.5)\n",
    "    if rows * cols < len(options):\n",
    "        rows += 1\n",
    "        \n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*6,rows*6), dpi=300)\n",
    "\n",
    "    axes = [axes] if isinstance(axes, Axes) else axes.flatten()\n",
    "\n",
    "\n",
    "    results = probabilistic_apy(datas, options, steps)\n",
    "\n",
    "    for opt, result, ax in zip(options, results, axes):\n",
    "        max_stakes = max([max(data) for data, count in zip(datas, opt[\"data_count\"]) if count])\n",
    "        stakes = np.linspace(0, max_stakes, 1000)\n",
    "        factor, prefix = factor_and_prefix(stakes[-1])\n",
    "        \n",
    "        tf_stakes = stake_transformation(stakes, **opt[\"model_arguments\"])\n",
    "\n",
    "        data_points = []\n",
    "        for data, count in zip(datas, opt[\"data_count\"]):\n",
    "            if not count:\n",
    "                continue\n",
    "            if count == \"all\":\n",
    "                data_points.extend(data)\n",
    "            else:\n",
    "                data_points.extend(random.sample(data, count))\n",
    "       \n",
    "        tf_data_points = stake_transformation(data_points, **opt[\"model_arguments\"])\n",
    "\n",
    "        stakes_for_plt = [s/factor for s in stakes]\n",
    "        tf_stakes_for_plt = [s/factor for s in tf_stakes]\n",
    "\n",
    "        data_points_for_plt = [s/factor for s in data_points]\n",
    "        tf_data_points_for_plt = [s/factor for s in tf_data_points]\n",
    "        \n",
    "        messages_per_second = opt[\"budget\"] / (opt[\"ticket_options\"][\"price\"] * opt[\"ticket_options\"][\"winning_probability\"]) / (opt[\"period_in_months\"] * 30 * 24 * 60 * 60)\n",
    "\n",
    "\n",
    "        ax.plot(stakes_for_plt, tf_stakes_for_plt, label=opt[\"legend\"])\n",
    "        ax.scatter(data_points_for_plt, tf_data_points_for_plt, s=12, alpha=0.8, c=\"#ff7f0e\")\n",
    "\n",
    "        ax.set_xlabel(f\"Stake (/{prefix}/HOPR)\")\n",
    "        ax.set_ylabel(f\"Transformed stake (/{prefix}/HOPR)\")\n",
    "        ax.text(0.1,\n",
    "                0.8,\n",
    "                f\"APY: {result['average']:.2%} (+- {result['std']:.2%})\",\n",
    "                transform=ax.transAxes, \n",
    "                horizontalalignment='left', \n",
    "                bbox=dict(facecolor='red', alpha=0.5),)\n",
    "        ax.text(0.1,\n",
    "                0.7,\n",
    "                f\"Messages/s: {messages_per_second:.2f}\",\n",
    "                transform=ax.transAxes, \n",
    "                horizontalalignment='left', \n",
    "                bbox=dict(facecolor='blue', alpha=0.5),)\n",
    "        \n",
    "        # set the x and y scale equal\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_ylim(ax.get_xlim())\n",
    "        \n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "    # remove unused axes\n",
    "    for ax in axes[len(options):]:\n",
    "        ax.remove()\n",
    "        \n",
    "    if title:\n",
    "        if len(options) == 1:\n",
    "            plt.title(title, fontsize=10)\n",
    "        else:\n",
    "            fig.suptitle(title, fontsize=20)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "def generate_simulation_graph_simple(options: list[dict], steps: int, title: str = None):\n",
    "    rows = 1\n",
    "    cols = int(len(options) / rows + 0.5)\n",
    "    if rows * cols < len(options):\n",
    "        cols += 1\n",
    "        \n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*6,rows*6), dpi=300)\n",
    "\n",
    "    axes = [axes] if isinstance(axes, Axes) else axes.flatten()\n",
    "\n",
    "    for opt, ax in zip(options, axes):        \n",
    "        stakes = np.linspace(0, 1e6, steps)\n",
    "        \n",
    "        tf_stakes = stake_transformation(stakes, **opt[\"model_arguments\"])\n",
    "        \n",
    "        ax.plot(stakes, tf_stakes)\n",
    "        ax.set_xlabel(f\"Stakes (HOPR)\")\n",
    "        ax.set_ylabel(f\"Transformed Stakes (HOPR)\")\n",
    "    \n",
    "        # set the x and y scale equal\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_ylim(ax.get_xlim())\n",
    "        \n",
    "        ax.grid()\n",
    "\n",
    "    # remove unused axes\n",
    "    for ax in axes[len(options):]:\n",
    "        ax.remove()\n",
    "        \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=20)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "def generate_simulation_table(datas:list[list], options: list[dict], imposed_counts: list, steps: int = 200):\n",
    "    \n",
    "    apy_array = []\n",
    "    messages_array = []\n",
    "    combined_array = []\n",
    "\n",
    "    for opt in options:\n",
    "        temp_apy_array = []\n",
    "        temp_messages_array = []\n",
    "        temp_combined_array = []\n",
    "\n",
    "        for count in imposed_counts:\n",
    "            opt[\"data_count\"] = count\n",
    "\n",
    "            result = probabilistic_apy(datas, [opt], steps)[0]\n",
    "            \n",
    "            messages_per_second = opt[\"budget\"] / (opt[\"ticket_options\"][\"price\"] * opt[\"ticket_options\"][\"winning_probability\"]) / (opt[\"period_in_months\"] * 30 * 24 * 60 * 60)\n",
    "\n",
    "            temp_apy_array.append(f\"{result['average']:.2%}\")\n",
    "            temp_messages_array.append(f\"{messages_per_second:.2f}\")\n",
    "            temp_combined_array.append(f\"{result['average']:.2%} / {messages_per_second:.2f}m/s\")\n",
    "\n",
    "        apy_array.append(temp_apy_array)\n",
    "        messages_array.append(temp_messages_array)\n",
    "        combined_array.append(temp_combined_array)\n",
    "\n",
    "    return apy_array, messages_array, combined_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_all = pd.read_csv(\"all_01H7Z22K1VRTXCWJJJFV2A64VP.csv\", low_memory=False)\n",
    "raw_nft = pd.read_csv(\"nft_01H7Z2W99SMWJ01YN552WSRADV.csv\", low_memory=False)\n",
    "\n",
    "raw_data = pd.merge(raw_all, raw_nft, on=\"account\", how=\"left\")\n",
    "\n",
    "condition = raw_data[\"token_id\"].isnull()\n",
    "\n",
    "staking_info_nft_holders = list(raw_data[~condition][\"actual_stake_x\"])\n",
    "staking_info_non_nft_holders = list(raw_data[condition][\"actual_stake_x\"])\n",
    "staking_info_all = list(raw_data[\"actual_stake_x\"])\n",
    "\n",
    "datas = [staking_info_nft_holders, staking_info_non_nft_holders, [500_000/0.05]]\n",
    "\n",
    "# aim for 15% APY\n",
    "prefered = {\n",
    "    \"data_count\": [\"all\", 0, 0],\n",
    "    \"budget\": 100_000, # fixed\n",
    "    \"period_in_months\": 1, # fixed\n",
    "    \"model_arguments\": {\n",
    "        \"slope\": 1, # fixed\n",
    "        \"curvature\":1.4,\n",
    "        \"threshold\":75e3,\n",
    "    },\n",
    "    \"ticket_options\": { # fixed\n",
    "        \"price\": 1, # fixed\n",
    "        \"winning_probability\": 1, # fixed\n",
    "    },\n",
    "    \"legend\": \"\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefered_vars = [deepcopy(prefered) for _ in range(5)]\n",
    "\n",
    "prefered_vars[0][\"data_count\"] = [250, 0, 0]\n",
    "prefered_vars[1][\"data_count\"] = [310, 0, 0]\n",
    "prefered_vars[2][\"data_count\"] = [370, 0, 0]\n",
    "prefered_vars[3][\"data_count\"] = [\"all\", 0, 0]\n",
    "prefered_vars[4][\"data_count\"] = [\"all\", \"all\", 0]\n",
    "\n",
    "for idx, opt in enumerate(prefered_vars[:-1]):\n",
    "    opt[\"legend\"] = f\"(month {idx})\"\n",
    "\n",
    "prefered_vars[-1][\"legend\"] = f\"(long-term)\"\n",
    "\n",
    "for idx, opt in enumerate(prefered_vars):\n",
    "    opt[\"legend\"] = f\"{opt['data_count'][0]} NFT and {opt['data_count'][1]} non-NFT holders\\n{opt['legend']}\"\n",
    "\n",
    "generate_simulation_graph(datas, prefered_vars, title=f\"Realistic scenario: 250 node runners day 1 + 15/week\\nbudget of {prefered_vars[0]['budget']/1000:.0f}k every {prefered_vars[0]['period_in_months']} month, ticket price at 0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apys = compute_apy(prefered, staking_info_nft_holders, percentage=True, average=False)\n",
    "average = np.mean([apy for apy, stake in zip(apys, staking_info_nft_holders) if stake > 10e3])\n",
    "\n",
    "print(f\"Average APY: {average}\")\n",
    "print(f\"Maximum APY: {max(apys)}\")\n",
    "\n",
    "plt.plot(staking_info_nft_holders, apys)\n",
    "plt.axhline(average, color=\"red\", linestyle=\"--\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_holder_counts = [200, \"all\"]\n",
    "options = [deepcopy(prefered) for _ in range(len(nft_holder_counts))]\n",
    "\n",
    "for opt, count in zip(options, nft_holder_counts):\n",
    "    opt[\"data_count\"][0] = count\n",
    "    opt[\"legend\"] = f\"{count} NFT holder\"\n",
    "\n",
    "options.append(deepcopy(prefered))\n",
    "\n",
    "options[-1][\"data_count\"] = [\"all\", \"all\", 0]\n",
    "options[-1][\"legend\"] = \"NFT holders and non-NFT holders\"\n",
    "\n",
    "\n",
    "generate_simulation_graph(datas, options, title=f\"Increasing network size (budget: {options[0]['budget']/1000:.0f}k, ticket price: {options[0]['ticket_options']['price']})\", cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes = [1, 0.75, 0.5]\n",
    "options_nft = [deepcopy(prefered) for _ in range(len(slopes))]\n",
    "\n",
    "for opt_nft, slope in zip( options_nft, slopes):\n",
    "    opt_nft[\"data_count\"] = [\"all\", 0, 0]\n",
    "    opt_nft[\"model_arguments\"][\"slope\"] = slope\n",
    "    opt_nft[\"legend\"] = f\"slope of {slope} (all NFT holders)\"\n",
    "\n",
    "generate_simulation_graph(datas, options_nft, 200, title=f\"Reducing slope (budget: {options[0]['budget']/1000:.0f}k, ticket price: {options[0]['ticket_options']['price']}, all NFT holders)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvatures = [1, 1.125, 1.25]\n",
    "options = [deepcopy(prefered) for _ in range(len(curvatures))]\n",
    "\n",
    "for opt, curvature in zip(options, curvatures):\n",
    "    opt[\"model_arguments\"][\"curvature\"] = curvature\n",
    "    opt[\"legend\"] = f\"curvature of {curvature}\"\n",
    "\n",
    "generate_simulation_graph(datas, options, 200, title=f\"Increasing curvature (budget: {options[0]['budget']/1000:.0f}k, ticket price: {options[0]['ticket_options']['price']}, all NFT holders)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
    "options = [deepcopy(prefered) for _ in range(len(ticket_prices))]\n",
    "\n",
    "for opt, ticket_price in zip(options, ticket_prices):\n",
    "    opt[\"ticket_options\"][\"price\"] = ticket_price\n",
    "    opt[\"legend\"] = f\"ticket price of {ticket_price}\"\n",
    "\n",
    "generate_simulation_graph(datas, options, title=f\"Increasing ticket price (budget: {options[0]['budget']/1000:.0f}k, all NFT holders)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [50e3, 100e3, 250e3]\n",
    "options = [deepcopy(prefered) for _ in range(len(thresholds))]\n",
    "\n",
    "for opt, threshold in zip(options, thresholds):\n",
    "    opt[\"model_arguments\"][\"threshold\"] = threshold\n",
    "    opt[\"legend\"] = f\"threshold at {ticket_price}\"\n",
    "\n",
    "\n",
    "generate_simulation_graph(datas, options, title=f\"Increasing threshold (budget: {options[0]['budget']/1000:.0f}k, ticket price: {options[0]['ticket_options']['price']}, all NFT holders)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [{\n",
    "    \"model_arguments\": {\n",
    "        \"slope\": 1,\n",
    "        \"curvature\":1.125,\n",
    "        \"threshold\":400e3,\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"model_arguments\": {\n",
    "        \"slope\": 1,\n",
    "        \"curvature\":1.125,\n",
    "        \"threshold\":750e3,\n",
    "    }\n",
    "}\n",
    "]\n",
    "\n",
    "generate_simulation_graph_simple(options, 5000, title=\"whale-threshold (c) at 400k vs 750k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [{\n",
    "    \"model_arguments\": {\n",
    "        \"slope\": 1,\n",
    "        \"curvature\":1.1,\n",
    "        \"threshold\":400e3,\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"model_arguments\": {\n",
    "        \"slope\": 1,\n",
    "        \"curvature\":1.200,\n",
    "        \"threshold\":400e3,\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"model_arguments\": {\n",
    "        \"slope\": 1,\n",
    "        \"curvature\":1.3,\n",
    "        \"threshold\":400e3,\n",
    "    }\n",
    "}\n",
    "]\n",
    "\n",
    "generate_simulation_graph_simple(options, 5000, title=\"increasing curvature parameter (b)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"min stake: {min(staking_info_nft_holders):.2f} HOPR\")\n",
    "print(f\"max stake: {max(staking_info_nft_holders):.2f} HOPR\")\n",
    "print(f\"average stake: {np.mean(staking_info_nft_holders):.2f} HOPR\")\n",
    "print(f\"median stake: {np.median(staking_info_nft_holders):.2f} HOPR\")\n",
    "print(f\"total reward: {sum(list(raw_data[~condition]['rewards_till_now'])):.2f} HOPR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
    "options = [deepcopy(prefered) for _ in range(len(ticket_prices))]\n",
    "\n",
    "for opt, ticket_price in zip(options, ticket_prices):\n",
    "    opt[\"data_count\"] = [\"all\", \"all\", 0]\n",
    "    opt[\"ticket_options\"][\"price\"] = ticket_price\n",
    "    opt[\"legend\"] = f\"ticket price of {ticket_price}\"\n",
    "\n",
    "generate_simulation_graph(datas, options, title=f\"Increasing ticket price (budget: {options[0]['budget']/1000:.0f}k, all NFT holders)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [\n",
    "    [250, 0, 0],\n",
    "    [310, 0, 0],\n",
    "    [370, 0, 0],\n",
    "    [\"all\", 0, 0],\n",
    "    [\"all\", \"all\", 0],\n",
    "]\n",
    "columns = [f\"{count[0]} NFT and {count[1]} non-NFT\" for count in counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvatures = [1, 1.125, 1.25, 1.375, 1.4, 1.5]\n",
    "rows = [f\"curvature: {curvature:.3f}\" for curvature in curvatures]\n",
    "options = [deepcopy(prefered) for _ in range(len(curvatures))]\n",
    "\n",
    "for opt, curvature in zip(options, curvatures):\n",
    "    opt[\"model_arguments\"][\"curvature\"] = curvature\n",
    "\n",
    "df_combined = pd.DataFrame(generate_simulation_table(datas, options, counts)[2], rows, columns)\n",
    "\n",
    "display(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [50e3, 75e3, 100e3, 150e3, 250e3]\n",
    "rows = [f\"threshold: {int(threshold/1e3)}k\" for threshold in thresholds]\n",
    "options = [deepcopy(prefered) for _ in range(len(thresholds))]\n",
    "\n",
    "for opt, threshold in zip(options, thresholds):\n",
    "    opt[\"model_arguments\"][\"threshold\"] = threshold\n",
    "\n",
    "df_combined = pd.DataFrame(generate_simulation_table(datas, options, counts)[2], rows, columns)\n",
    "\n",
    "display(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
    "rows = [f\"ticket price: {price}\" for price in ticket_prices]\n",
    "options = [deepcopy(prefered) for _ in range(len(ticket_prices))]\n",
    "\n",
    "for opt, price in zip(options, ticket_prices):\n",
    "    opt[\"ticket_options\"][\"price\"] = price\n",
    "\n",
    "df_combined = pd.DataFrame(generate_simulation_table(datas, options, counts)[2], rows, columns)\n",
    "\n",
    "display(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, axes = plt.subplots(2, 3, figsize=(14, 8), dpi=300, sharey=True)\n",
    "axes = axes.flatten()\n",
    "options = deepcopy(prefered_vars)\n",
    "\n",
    "for opt, ax in zip(options, axes):\n",
    "    stakes = []\n",
    "\n",
    "    for data, count in zip(datas, opt[\"data_count\"]):\n",
    "        if not count:\n",
    "            continue\n",
    "        if count == \"all\":\n",
    "            stakes.extend(data)\n",
    "        else:\n",
    "            stakes.extend(random.sample(data, count))        \n",
    "\n",
    "    stakes = sorted(stakes)\n",
    "\n",
    "    lin_range = np.linspace(0, max(stakes), 1000)\n",
    "\n",
    "    apys = compute_apy(opt, stakes, percentage=True, average=False, on_stake=True)\n",
    "    global_apy = probabilistic_apy(datas, [opt], steps=200)[0][\"average\"] * 100\n",
    "\n",
    "    rewards = [apy*stake/100 / 12 for apy, stake in zip(apys, stakes)]\n",
    "    \n",
    "    average_reward = np.mean([reward for reward, stake in zip(rewards, stakes) if stake > 10e3])\n",
    "    median_reward = np.median([reward for reward, stake in zip(rewards, stakes) if stake > 10e3])\n",
    "\n",
    "    factor, prefix = factor_and_prefix(stakes[-1])\n",
    "\n",
    "    stakes = [s/factor for s in stakes]\n",
    "    \n",
    "    ax.plot(stakes, rewards, alpha=0.5)\n",
    "    ax.scatter(stakes, rewards, s=8, c=\"#ff7f0e\", alpha=0.5)\n",
    "    ax.text(0.95,\n",
    "            0.85,\n",
    "            opt[\"legend\"],\n",
    "            transform=ax.transAxes,\n",
    "            horizontalalignment='right')    \n",
    "    ax.text(0.95,\n",
    "            0.2,\n",
    "            f\"Median reward: {median_reward:.2f} HOPR\",\n",
    "            transform=ax.transAxes,\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(facecolor='orange', alpha=0.5),)\n",
    "    ax.text(0.95,\n",
    "            0.1,\n",
    "            f\"Average reward: {average_reward:,.2f} HOPR\",\n",
    "            transform=ax.transAxes,\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(facecolor='orange', alpha=0.5),)\n",
    "    \n",
    "\n",
    "    ax.set_xlabel(f\"Stake (/{prefix}/HOPR)\")\n",
    "    ax.set_ylabel(\"Reward (HOPR)\")\n",
    "\n",
    "# remove unused subplots\n",
    "for ax in axes[len(options):]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, axes = plt.subplots(2, 3, figsize=(14, 8), dpi=300, sharey=True)\n",
    "axes = axes.flatten()\n",
    "options = deepcopy(prefered_vars)\n",
    "\n",
    "for opt, ax in zip(options, axes):\n",
    "    stakes = []\n",
    "\n",
    "    for data, count in zip(datas, opt[\"data_count\"]):\n",
    "        if not count:\n",
    "            continue\n",
    "        if count == \"all\":\n",
    "            stakes.extend(data)\n",
    "        else:\n",
    "            stakes.extend(random.sample(data, count))        \n",
    "\n",
    "    stakes = sorted(stakes)\n",
    "\n",
    "    lin_range = np.linspace(0, max(stakes), 1000)\n",
    "\n",
    "    apys = compute_apy(opt, stakes, percentage=True, average=False, on_stake=True)\n",
    "    global_apy = probabilistic_apy(datas, [opt], steps=200)[0][\"average\"] * 100\n",
    "    \n",
    "    average_apy = np.mean([apy for apy, stake in zip(apys, stakes) if stake > 10e3])\n",
    "    median_apy = np.median([apy for apy, stake in zip(apys, stakes) if stake > 10e3])\n",
    "\n",
    "    factor, prefix = factor_and_prefix(stakes[-1])\n",
    "\n",
    "    stakes = [s/factor for s in stakes]\n",
    "    \n",
    "    ax.plot(stakes, apys, alpha=0.5)\n",
    "    ax.scatter(stakes, apys, s=8, c=\"#ff7f0e\", alpha=0.5)\n",
    "    ax.text(0.95,\n",
    "            0.85,\n",
    "            opt[\"legend\"],\n",
    "            transform=ax.transAxes,\n",
    "            horizontalalignment='right')    \n",
    "    ax.text(0.95,\n",
    "            0.75,\n",
    "            f\"Average APY: {average_apy:,.2f} %\",\n",
    "            transform=ax.transAxes,\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(facecolor='orange', alpha=0.5),)\n",
    "    ax.text(0.95,\n",
    "        0.65,\n",
    "        f\"Median APY: {median_apy:,.2f} %\",\n",
    "        transform=ax.transAxes,\n",
    "        horizontalalignment='right',\n",
    "        bbox=dict(facecolor='orange', alpha=0.5),)\n",
    "\n",
    "    ax.set_xlabel(f\"Stake (/{prefix}/HOPR)\")\n",
    "    ax.set_ylabel(\"APY (%)\")\n",
    "\n",
    "# remove unused subplots\n",
    "for ax in axes[len(options):]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_node_count = [1, 25, 50, 100, 133, 400]\n",
    "hopr_value = 0.05\n",
    "investor_budget = 0.5e6 / hopr_value\n",
    "\n",
    "def split_to_buckets(value, bucket_count, min_amount, max_amount):\n",
    "    average = value / bucket_count\n",
    "\n",
    "    if max_amount >= average and average >= min_amount:\n",
    "        return [average] * bucket_count\n",
    "    \n",
    "    if average < min_amount:\n",
    "        return split_to_buckets(value, bucket_count-1, min_amount, max_amount) + [0]\n",
    "    \n",
    "    filled_buckets = min(int(value / max_amount), bucket_count -1)\n",
    "    remaining_value = value - filled_buckets * max_amount\n",
    "    remaining_buckets = bucket_count - filled_buckets\n",
    "\n",
    "    return [max_amount] * filled_buckets + split_to_buckets(remaining_value, remaining_buckets, min_amount, max_amount*2)\n",
    "\n",
    "for node_count in investor_node_count:\n",
    "    datas = [staking_info_nft_holders, staking_info_non_nft_holders, [investor_budget / node_count]*node_count]\n",
    "\n",
    "    options = [deepcopy(prefered) for _ in range(2)]\n",
    "\n",
    "    options[0][\"data_count\"] = [\"all\", 0, \"all\"]\n",
    "    options[1][\"data_count\"] = [\"all\", \"all\", \"all\"]\n",
    "\n",
    "    apys = probabilistic_apy(datas, options, 200)\n",
    "\n",
    "    print(f\"Investor with {int(investor_budget):,}HOPR and {node_count} nodes in the network\")\n",
    "    for idx, (opt, apy) in enumerate(zip(options, apys)):\n",
    "        opt[\"legend\"] = f\"{opt['data_count'][0]} NFT and {opt['data_count'][1]} non-NFT holders {opt['data_count'][2]} investors nodes \"\n",
    "\n",
    "        if opt[\"data_count\"][2] == \"all\":\n",
    "            tf_stakes = stake_transformation(datas[2], **opt[\"model_arguments\"])\n",
    "        else:\n",
    "            tf_stakes = [0]\n",
    "\n",
    "        reward = [tf_stake * apy[\"average\"] for tf_stake in tf_stakes] \n",
    "\n",
    "        print(f\"    {opt['legend']}: {sum(reward):,.2f}HOPR -> {sum(reward)/investor_budget:.2%} APY (network APY: {apy['average']:.2%})\")\n",
    "\n",
    "\n",
    "    # generate_simulation_graph(datas, options, title=f\"Realistic scenario: 250 node runners day 1 + 15/week\\nbudget of {prefered_vars[0]['budget']/1000:.0f}k every {prefered_vars[0]['period_in_months']} month, ticket price at 0.001\", cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas = [staking_info_nft_holders, staking_info_non_nft_holders, [investor_budget / node_count]*node_count]\n",
    "\n",
    "ct_candidates = [stake for stake in staking_info_all if stake > 10e3]\n",
    "median_staker = ct_candidates[len(ct_candidates)//2]\n",
    "\n",
    "median_stakes = [median_staker]\n",
    "\n",
    "datas = [staking_info_nft_holders, staking_info_non_nft_holders, 0]\n",
    "\n",
    "options = [deepcopy(prefered) for _ in range(2)]\n",
    "\n",
    "options[0][\"data_count\"] = [\"all\", 0, 0]\n",
    "options[1][\"data_count\"] = [\"all\", \"all\", 0]\n",
    "\n",
    "apys = probabilistic_apy(datas, options, 200)\n",
    "\n",
    "print(f\"{median_staker:,}HOPR staker with {1} nodes in the network\")\n",
    "for idx, (opt, apy) in enumerate(zip(options, apys)):\n",
    "    tf_stakes = stake_transformation(median_stakes, **opt[\"model_arguments\"])\n",
    "\n",
    "    reward = [tf_stake * apy[\"average\"] for tf_stake in tf_stakes] \n",
    "    \n",
    "    print(f\"    : {sum(reward):,.2f}HOPR -> {sum(reward)/sum(median_stakes):.2%} APY (network APY: {apy['average']:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apy[\"average\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(staking_info_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
